<h3 align = "center"> Proyecto Despliegue - Big Data </h3>

---
<p align = "center"> Este proyecto consiste en un conjunto de scripts dise帽ados para recopilar datos financieros de diversas acciones de la bolsa de valores y posteriormente obtener informaci贸n acerca de ellos. 
Estos datos incluyen el nombre de la acci贸n, la 煤ltima cotizaci贸n, el m谩ximo y m铆nimo de la sesi贸n, y la fecha y hora de la recopilaci贸n.
<br>
</p>

##  Tabla de contenido

- [Estructura del proyecto](#structure)
- [Recopilando datos](#extract_data)
- [Gestionando datos](#manage_data)
- [Autores](#authors)

## 锔 Estructura del Proyecto <a name = "structure"> </a>

El proyecto se organiza de la siguiente manera en local:

- **src**: Contiene el c贸digo fuente del proyecto.
  - **extract**: Directorio que contiene los scripts de extracci贸n de datos.
  - **datos**: Directorio donde se almacenan los datos recopilados.
  - **management**: Directorio donde se almacenan los scripts para procesar los datos de forma local.
    - **hdfs**: Directorio donde se almacenan los scripts usando HDFS.

Los archivos que se almacenan en datos tienen la forma de `DD-MM-YYYY.csv` donde sus campos son en orden de izquierda a derecha:
- Nombre de la Acci贸n
- ltima cotizaci贸n
- M谩ximo de la sesi贸n
- M铆nimo de la sesi贸n
- Hora

El archivo que se encuentra en src con nombre `informacion_empresas.csv` sus campos de izquierda a derecha son:
- Nombre de la empresa
- Fecha de fundaci贸n
- Tipo de empresa
- N煤mero de empleados
- Beneficio neto
- Ciudad donde tienen la sede central

En HDFS el proyecto tiene la siguiente forma:

- **proyecto_despliegue**: Contiene los archivos necesarios para su ejecuci贸n en hdfs.
  - **datos**: Directorio donde se almacenan los datos recopilados al terminar el d铆a.


##  Extrayendo datos <a name = "extract_data"> </a>

El script `dataExtraction.sh` se encarga de ejecutar el script de scraping autom谩ticamente cada hora durante el horario comercial (de 9:30 a 18:30 de lunes a viernes). Los datos recopilados se guardan en el directorio `datos` y al finalizar el d铆a se subir谩 al directorio HDFS `proyecto_despliegue/datos`.

El nombre de los archivos es la fecha en formato DD-MM-YYYY y se recopilan cada hora.

### Requisitos previos

Qu茅 necesita para instalar el software y c贸mo instalarlo.
Lo que se debe instalar para hacer funcionar este proyecto es una m谩quina Linux con Apache Hadoop con HDFS configurado.

Adem谩s, deber谩 instalar selenium ejecutando en su terminal el siguiente comando:

```
pip install selenium
```

### Uso del script

Para poner el script en funcionamiento, deber谩 seguir los siguientes pasos:

1. Iniciar el servicio HDFS

```
start-dfs.sh
```

2. Acceder a la carpeta extract del repositorio previamente clonado

```
cd 4B_BigData_Despliegue/src/extract/
```

3. Dar permisos de ejecuci贸n a los siguientes ficheros

```
chmod +x dataExtraction.sh
```
```
chmod +x scraper.py
```
```
chmod +x geckodriver
```

4. Ejecutar el fichero

```
sh dataExtraction.sh
```

##  Gestionando datos <a name = "manage_data"> </a>

El la carpeta `management` est谩n todo lo archivos relacionados con la gesti贸n de los `datos` junto a un archivo `.sh` encargado de la mecanizaci贸n de procesos.

### Descipci贸n de los script

- `Ejercicio 1`: Genera un lista semanal donde se indica (`Nombre de la acci贸n`, (`valor inicial de cotizaci贸n`, `valor final de cotizaci贸n`, `m铆nimo`, `m谩ximo`))

- `Ejercicio 2`: Genera un lista mensual donde se indica (`Nombre de la acci贸n`, (`valor inicial de cotizaci贸n`, `valor final de cotizaci贸n`, `m铆nimo`, `m谩ximo`))

- `Ejercicio 3`: Dado el nombre de una acci贸n y un rango ded fechas, obtiene (`Acci贸n`, (`valor m铆nimo de cotizaci贸n`, `valor m谩ximo de cotizaci贸n`, `porcentaje de decremento desde el valor inicial hasta el m铆nimo`, `porcentaje de incremento desde el valor inicial hasta el m谩ximo`))

- `Ejercicio 4`: Dado el nombre de una acci贸n se obtiene (`Acci贸n`, (`valor m铆nimo mensual`, `valor m谩ximo mensual`, `valor m铆nimo semanal`, `valor m谩ximo semanal`, `valor m铆nimo de la 煤ltima hora`, `valor m谩ximo de la 煤ltima hora`))

- `Ejercicio 5`: Muestra las 5 acciones que m谩s han subido en la 煤ltima semana y 煤ltimo mes: (`Semana/Mes`, (`Nombre de la acci贸n`, `diferencia de la acci贸n (precio final-precio inicial)`))

- `Ejercicio 6`: Muestra las 5 acciones que m谩s han bajado en la 煤ltima semana y 煤ltimo mes: (`Semana/Mes`, (`Nombre de la acci贸n`, `diferencia de la acci贸n (precio final-precio inicial)`))

- `Ejercicio 7`: Dado un porcentaje y un rango de fechas obtiene las acciones que han tenido un incremento de ese porcentaje durante ese periodo (`Acci贸n`, (`Porcentaje de incremento del precio de la acci贸n`, `Porcentaje introducido`))

- `Extra 1`: Ranking de las acciones con mayor ratio entre la 煤ltima cotizaci贸n y el beneficio econ贸mico de esa empresa, sirve para saber si una acci贸n est谩 sobrevalorada (`Posici贸n del ranking`, (`Nombre de la acci贸n`, `Ratio`))

- `Extra 2`: Muestra el tipo de empresa que tiende a tener acciones m谩s altas (`Tipo de empresa`, `Cotizaci贸n media de ese tipo de empresa`)

- `Extra 3`: Muestra la acci贸n de las empresa fundada antes de los 2000 que tiene el menor porcentaje de incremento de cotizaci贸n en un d铆a (`Nombre de la Acci贸n`, `Porcentaje de incremento de cotizaci贸n`)

### Requisitos previos <a name = "previous_steps_manage"> </a>

Si se van a ejecutar de forma local puede omitir este apartado y pasar al funcionamiento local, sin embargo para HDFS ser谩 necesario ejecutar el servicio de HDFS y YARN.

```
start-dfs.sh
```

```
start-yarn.sh
```

### Funcionamiento en su m谩quina local

1. Situarse en el `directorio management`

```
cd src/management
```

2. Para ejecutar los scripts del ejercicio 1 al ejercicio 7

```
sh ejercicioX.sh
```
Donde X es el n煤mero del 1 al 7

3. Para ejecutar los scripts extra 

```
python extraX.py ../informacion_empresas.csv ../datos/DD-MM-YYYY.csv 
```
Donde `X` es el n煤mero del 1 al 3 y `DD-MM-YYY` es el formato del archivo diario que quiera consultar

### Funcionamiento en HDFS

Para esta parte es necesario haber ejecutado los comandos que aparecen en [`Requisitos previos`](#previous_steps_manage)

1. Subir a HDFS el archivo con la informaci贸n de las empresas situado en `src`

```
cd src/
```

```
hdfs dfs -put informacion_empresas.csv proyecto_despliegue
```

2. Situarse en el directorio `hdfs`

```
cd src/management/hdfs
```

3. Para ejecutar los scripts del ejercicio 1 al ejercicio 7

```
sh ejercicioX.sh
```
Donde `X` es el n煤mero del 1 al 7

4. Para ejecutar los scripts extra 

```
python extraX.py -r hadoop hdfs:///user/alumno/proyecto_despliegue/informacion_empresas.csv hdfs:///user/alumno/proyecto_despliegue/datos/DD-MM-YYYY.csv
```
Y si quiere que la informaci贸n se guarde en un archivo puede a帽adirle esto:

```
--output-dir proyecto_despliegue/extraX
```

Donde `X`es el n煤mero del 1 al 3 y `DD-MM-YYY` es el formato del archivo diario que quiera consultar


## 锔 Autores <a name = "authors"> </a>

* **Claudia Torres** - [ClaudiaTC02](https://github.com/ClaudiaTC02)
* **Jordi Dom茅nech** - [Jordi272](https://github.com/Jordi272)
