<h3 align = "center"> Proyecto Despliegue - Big Data </h3>

---
<p align = "center"> Este proyecto consiste en un conjunto de scripts dise침ados para recopilar datos financieros de diversas acciones de la bolsa de valores. Estos datos incluyen el nombre de la acci칩n, la 칰ltima cotizaci칩n, el m치ximo y m칤nimo de la sesi칩n, y la fecha y hora de la recopilaci칩n.
    <br>
</p>

## 游닇 Tabla de contenido

- [Estructura del proyecto](#structure)
- [Recopilando datos](#extract_data)

## 丘뉦잺 Estructura del Proyecto <a name = "structure"> </a>

El proyecto se organiza de la siguiente manera:

- **src**: Contiene el c칩digo fuente del proyecto.
  - **extract**: Directorio que contiene los scripts de extracci칩n de datos.
  - **datos**: Directorio donde se almacenan los datos recopilados.


## 游끠 Extrayendo datos <a name = "extract_data"> </a>

El script `dataExtraction.sh` se encarga de ejecutar el script de scraping autom치ticamente cada hora durante el horario comercial (de 9:30 a 18:30 de lunes a viernes). Los datos recopilados se guardan en el directorio `datos` y al finalizar el d칤a se subir치 al directorio HDFS `proyecto_despliegue/datos`.

El nombre de los archivos es la fecha en formato DD-MM-YYYY y se recopilan cada hora.

### Requisitos previos

Qu칠 necesita para instalar el software y c칩mo instalarlo.
Lo que se debe instalar para hacer funcionar este proyecto es una m치quina Linux con Apache Hadoop con HDFS configurado.

Adem치s, deber치 instalar selenium ejecutando en su terminal el siguiente comando:

```
pip install selenium
```

### Uso del script

Para poner el script en funcionamiento, deber치 seguir los siguientes pasos:

1. Iniciar el servicio HDFS

```
start-dfs.sh
```

2. Acceder a la carpeta extract del repositorio previamente clonado

```
cd 4B_BigData_Despliegue/src/extract/
```

1. Dar permisos de ejecuci칩n a los siguientes ficheros

```
chmod +x dataExtraction.sh
```
```
chmod +x scraper.py
```
```
chmod +x geckodriver
```

4. Ejecutar el fichero

```
sh dataExtraction.sh
```